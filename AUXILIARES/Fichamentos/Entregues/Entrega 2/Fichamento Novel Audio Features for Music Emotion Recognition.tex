\documentclass{article}
\usepackage[utf8]{inputenc}
\title{Fichamento}
\author{GABRIEL PRÓSPERO REALIZADOR  SILVA}
\date{Abril 2021}

\usepackage{natbib}
\usepackage{graphicx}
\begin{document}
\maketitle

\section{DADOS DO ARTIGO}
\textbf{Novel Audio Features for Music Emotion Recognition \\}
\author{Renato Panda \\}
\date{2018}

\section{RESENHA}
Freqüentemente, argumenta-se que os paradigmas dimensionais levam a uma menor ambiguidade, uma vez que, em vez de ter um conjunto discreto de adjetivos de emoção, as emoções são consideradas um continuum [10] Um modelo dimensional amplamente aceito em MER é o modelo circunplexo de James Russell [13].
As duas dimensões propostas são valência (agradável-desagradável) e atividade ou excitação (excitado-não excitado), ou AV. O plano bidimensional resultante forma quatro quadrantes diferentes: 1- exuberância, 2- ansiedade, 3- depressão e 4- contentamento (Fig. 1).
Ainda assim, acreditamos que estimar coisas como linhas melódicas predominantes, mesmo que imperfeitas, nos dá informações relevantes que atualmente não são utilizadas no MER. Para tanto, nos baseamos em trabalhos anteriores de Salomon et al. [38] e Dressler [39] para estimar as frequências fundamentais predominantes (f0) e saliências. Normalmente, o processo começa identificando quais frequências estão presentes no sinal em cada ponto no tempo (extração da sinusóide).
Até onde sabemos, textura musical é o conceito musical com recursos de áudio menos diretamente relacionados disponíveis (Seção). No entanto, alguns estudos demonstraram que pode influenciar a emoção na música diretamente ou interagindo com outros conceitos, como tempo e modo [42]. 
Articulação é uma técnica que afeta a transição ou continuidade entre notas ou sons. Para calcular os recursos de articulação, começamos detectando legato (ou seja, notas conectadas tocadas "suavemente") e staccato (ou seja, notas curtas e destacadas), conforme descrito em Algoritmo. Usando isso, classificamos todos os
transições entre notas no clipe da música e, a partir delas, extraia várias métricas como: proporção de staccato, legato e outras transições, sequência mais longa de cada tipo de articulação, etc.
Alguns pesquisadores estudaram a emoção na fala e na voz cantada [47] e até estudaram as características acústicas relacionadas [48]. Na verdade, "usar apenas as vozes cantadas pode ser eficaz para separar a emoção" calma "da" triste ", mas essa eficácia é perdida quando as vozes são misturadas com a música de acompanhamento" e "a separação da fonte pode efetivamente melhorar a desempenho ”[9].
Isso parece indicar que as emoções com maior excitação são mais fáceis de diferenciar com as características selecionadas.
Além disso, os sujeitos relataram ter mais dificuldade em distinguir valência para canções com baixa excitação. Além disso, algumas músicas desses quadrantes parecem compartilhar características musicais, que estão relacionadas a elementos emocionais contrastantes (por exemplo, um acompanhamento ou melodia feliz e uma voz ou letra triste).


\section{PLAVRAS-CHAVES}
\begin{itemize}
    \item Music Information Retrieval (MIR)
    \item MIREX AMC
    \item Arousal, valence and dominance (AVD)
    \item extração da sinusóide
    \item função de saliência do tom
\end{itemize}

\end{document}

