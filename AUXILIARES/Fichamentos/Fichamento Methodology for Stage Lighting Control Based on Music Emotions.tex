\documentclass{article}
\usepackage[utf8]{inputenc}
\title{Fichamento}
\author{GABRIEL PRÓSPERO REALIZADOR  SILVA}
\date{Março 2021}

\usepackage{natbib}
\usepackage{graphicx}
\begin{document}
\maketitle

\section{DADOS DO ARTIGO}
\textbf{Methodology for Stage Lighting Control Based on Music Emotions \\}
\author{AUTOR \\}
\date{DATA EM QUE O ARTIGO FOI FEITO}

\section{RESENHA}
é difícil usar um pequeno número de adjetivos para cobrir todas as expressões possíveis de emoção musical. Além disso, pessoas com origens culturais diferentes interpretam os adjetivos de maneira diferente. Portanto, os pesquisadores começaram a buscar um meio geral e eficiente de expressar as emoções musicais. Um modelo de emoção, conhecido como modelo de Thayer, que se baseia em expressões de emoção lineares e contínuas, agora é usado com frequência.

No campo do reconhecimento automático de padrões, um algoritmo de aprendizado supervisionado para classificar propriedades é indispensável. No campo da pesquisa de reconhecimento de emoção musical, alguns algoritmos têm sido usados ​​para aprendizagem, tais como SVM [3], SVR [48,49], fuzzy C-Mean [30], modelos de mistura gaussiana (GMMs) [24], multi perceptrons de camada (MLPs), modelo de Markov oculto (HMM) [1], vizinho K-mais próximo (KNN) [21,44], AdaBoost [50] e redes neurais de base de função radial (RBFNNs) [3].

Uma solução para resolver este problema é utilizar o PCA, que normalmente é usado para aumentar a eficiência e melhorar a precisão, eliminando dados irrelevantes [4]

PCA é um procedimento estatístico que usa uma transformação ortogonal para converter um conjunto de observações de variáveis ​​possivelmente correlacionadas em um conjunto de valores de variáveis ​​lineares não correlacionadas.
Esta transformação é definida de modo que o primeiro componente principal tenha a maior variância possível (ou seja, ele é responsável pelo máximo possível da variabilidade nos dados), e cada componente sucessivo, por sua vez, tem a maior variância possível sob a restrição de que é ortogonal (ou seja, não correlacionado com) aos componentes anteriores.

Os SVMs constituem uma das técnicas mais poderosas de classificação supervisionada. No entanto, seu desempenho depende da escolha das funções de kernel apropriadas ou dos parâmetros apropriados de uma função de kernel.





\section{PLAVRAS-CHAVES}
\begin{itemize}
    \item music emotion recognition (MER)
    \item Thayer’s emotion plane
    \item support vector regression (SVR)
    \item Kansei Engineering measurement approach
    \item linear prediction coefficients (LPC)
    \item linear prediction cepstrum coefficients (LPCC)
    \item mel-frequency cepstrum coefficients (MFCC)
    \item cepstros
    \item roll-off
    \item multiple linear regression (MLR)
    \item principal component analysis
    \item cross-validation (CV)
    \item kernel RBF
\end{itemize}

\end{document}

