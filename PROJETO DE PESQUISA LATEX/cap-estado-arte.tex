\chapter{Estado da arte}

Reconhecimento de cover é uma subárea do MIR (music information retrieval) e, de maneira grosseira, pode ser resumido em duas fases cruciais, a extração de recursos relevantes do áudio, e manipulação correta dos recursos extraídos, na respectiva ordem colocada. 

O sinal de áudio é frequentemente chamado de áudio bruto, em comparação com outras representações que são transformações baseadas nele \cite{Choi2018}, deste, as informações do áudio podem ser extraídas. A maioria das abordagens de aprendizado profundo em MIR tira proveito de representações bidimensionais em vez da representação unidimensional original que é o sinal de áudio bruto, e em muitos casos, as duas dimensões são eixos de frequência e tempo \cite{Choi2018}.

A fase de manipular os recursos extraídos em prol do reconhecimento de cover pode variar em vários fatores de acordo com a abordagem adotada. Um dos fatores importantes no reconhecimento de cover é a métrica de distância aplicada. Uma métrica de distância mede a similaridade de subsequências no espaço de recurso dentro de duas peças musicais \cite{Chang2017} diferentes ou não. 

No processo de reconhecer covers CHANG et al. primeiro converte os sinais de áudio de cada música em recursos de croma de 12 dimensões com uma janela não sobreposta de 1 segundo (fase de extração), usa como métrica de distância a matriz de similaridade cruzada e aplica CNN nas matrizes adjacentes geradas das comparações musicais. CHANG et al. supõe que uma rede neural possa identificar e aprender padrões inerentes da música original que não se perdem no cover \cite{Chang2017}. As matrizes de similaridade requerem espaço quadrático em relação ao comprimento do vetor de recursos usado para descrever o áudio. Por esse motivo, a maioria dos métodos usados para encontrar padrões na matriz de similaridade são (pelo menos) quadráticos em complexidade de tempo \cite{8392419}. Para melhorar o desempenho do processo de reconhecimento de cover, SILVA et al. propõe uma simplificação dessa matriz pois o mesmo acredita que a maioria das informações contidas em matrizes de similaridade seja irrelevante ou com pouco impacto em sua análise \cite{8392419}.Tomando essa ideia como base SILVA et al. propõe o SiMPle (Similarity Matrix ProfiLE), uma versão otimizada das matrizes de similaridade. Os recursos de croma foram usados, mas segundo o artigo, diferentes conjuntos de recursos podem ser utilizados. Para calcular o SIMPle, SILVA et al. sugere o uso do SIMPLe-fast, e posteriormente a média do SIMPLe gerado é usada para ligar o cover a música. SERRÀ, J. et al. também usa recursos de croma para comparar músicas diferentes. Inicialmente se extrai séries temporais do croma que representam sua progressão tonal \cite{Serra2009}. Essas séries temporais são então usadas para incorporação multivariada por meio de coordenadas de atraso \cite{Serra2009}. Para avaliar equivalências de estados entre os dois sistemas obtidos em momentos diferentes, foram usados CRP (Cross Recurrence Plot) e medidas de quantificação de recorrência derivadas deles \cite{Serra2009}. Na pré-análise, as medidas de quantificação de recorrência existentes foram avaliadas usando o KNN (k-nearest neighbors algorithm) \cite{Serra2009} e métricas de precisão no padrão IR (Information Retrieval), como o MAP (Mean Average Precision).

CHENG, Y et al. tenta uma abordagem diferente, ele propõe extração de recursos de arquivos MIDI (Musical Instrument Digital Interface). MIDI é um padrão técnico que permite uma ampla variedade de instrumentos musicais eletrônicos se conectarem, e se comunicarem entre si, e que também fornece uma forma de representação simbólica para a música \cite{10.1145/3077136.3080680}. O MIDI é outra fonte de extração de recursos para o reconhecimento de cover. O processo de extração de pitch é mais preciso em arquivos MIDI originais do que em arquivos de áudio, no entanto, arquivos MIDI originais geralmente são difíceis de serem acessados por motivos de direitos autorais \cite{10.1145/3077136.3080680}. Para extrair os recursos, primeiramente CHENG, Y et al. converte o sinal de áudio em MIDI, e nesse processo algumas informações relevantes podem ser perdidas \cite{10.1145/3077136.3080680}. Os recursos extraídos são chamados de NCP, a métrica de precisão adotada é o MAP (Mean Average Precision) e o algoritmo Q * MAX para tomar as decisões. 

PONIGHZWA, R. M. F. et al., busca seus recursos no padrão MPEG-7 e propõe usar 2 recursos de extração: a projeção do espectro de áudio e o nivelamento do espectro de áudio \cite{8257086}. Para o reconhecimento de cover é usado o algoritimo KNN (k-nearest neighbors algorithm) modificado e a métrica de acurácia é uma modificação aparente, do MAP (Mean Average Precision).


